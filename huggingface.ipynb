{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as tf_text\n",
    "tf.disable_eager_execution()\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, SimpleRNN\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.utils import to_categorical\n",
    "import gensim\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from keras.callbacks import callbacks\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from transformers import XLMTokenizer, XLMWithLMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../NADI-2020_release_1.0/NADI_release/train_labeled.tsv',sep='\\t')\n",
    "dev_df = pd.read_csv('../NADI-2020_release_1.0/NADI_release/dev_labeled.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original,y_train_original = train_df[\"#2 tweet_content\"],train_df[\"#3 country_label\"]\n",
    "X_dev_original,y_dev_original = dev_df[\"#2 tweet_content\"],dev_df[\"#3 country_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {}\n",
    "uni = y_train_original.unique()\n",
    "for i in range(len(uni)):\n",
    "    labels[uni[i]] = i\n",
    "\n",
    "y_train_index = [labels[i] for i in y_train_original]\n",
    "y_dev_index = [labels[i] for i in y_dev_original]\n",
    "\n",
    "y_train = to_categorical(y_train_index, num_classes=21)\n",
    "y_dev = to_categorical(y_dev_index, num_classes=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc6c76a4e0d34a66aaeec01eb5e8938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=5715183.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4291377f0c444f99df277db4023a069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2973279.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLMTokenizer.from_pretrained(\"xlm-mlm-100-1280\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'af': 0, 'als': 1, 'am': 2, 'an': 3, 'ang': 4, 'ar': 5, 'arz': 6, 'ast': 7, 'az': 8, 'bar': 9, 'be': 10, 'bg': 11, 'bn': 12, 'br': 13, 'bs': 14, 'ca': 15, 'ceb': 16, 'ckb': 17, 'cs': 18, 'cy': 19, 'da': 20, 'de': 21, 'el': 22, 'en': 23, 'eo': 24, 'es': 25, 'et': 26, 'eu': 27, 'fa': 28, 'fi': 29, 'fr': 30, 'fy': 31, 'ga': 32, 'gan': 33, 'gl': 34, 'gu': 35, 'he': 36, 'hi': 37, 'hr': 38, 'hu': 39, 'hy': 40, 'ia': 41, 'id': 42, 'is': 43, 'it': 44, 'ja': 45, 'jv': 46, 'ka': 47, 'kk': 48, 'kn': 49, 'ko': 50, 'ku': 51, 'la': 52, 'lb': 53, 'lt': 54, 'lv': 55, 'mk': 56, 'ml': 57, 'mn': 58, 'mr': 59, 'ms': 60, 'my': 61, 'nds': 62, 'ne': 63, 'nl': 64, 'nn': 65, 'no': 66, 'oc': 67, 'pl': 68, 'pt': 69, 'ro': 70, 'ru': 71, 'scn': 72, 'sco': 73, 'sh': 74, 'si': 75, 'simple': 76, 'sk': 77, 'sl': 78, 'sq': 79, 'sr': 80, 'sv': 81, 'sw': 82, 'ta': 83, 'te': 84, 'th': 85, 'tl': 86, 'tr': 87, 'tt': 88, 'uk': 89, 'ur': 90, 'uz': 91, 'vi': 92, 'war': 93, 'wuu': 94, 'yi': 95, 'zh': 96, 'zh_classical': 97, 'zh_min_nan': 98, 'zh_yue': 99}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.lang2id)#'ar': 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = torch.tensor([tokenizer.encode(X_train_original[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 57])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_id = tokenizer.lang2id['ar']\n",
    "langs = torch.tensor([language_id] * input_ids.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = langs.view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-8e2ff35acf64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXLMWithLMHeadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'config'"
     ]
    }
   ],
   "source": [
    "model = XLMWithLMHeadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-9abe135d136c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlangs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlangs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "outputs = model(input_ids, langs=langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
